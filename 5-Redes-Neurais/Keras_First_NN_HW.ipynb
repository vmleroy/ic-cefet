{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.282</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.207</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>90</td>\n",
       "      <td>51</td>\n",
       "      <td>220</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.325</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>8</td>\n",
       "      <td>91</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.587</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.127</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "332               1                     180               0               0   \n",
       "106               1                      96             122               0   \n",
       "99                1                     122              90              51   \n",
       "674               8                      91              82               0   \n",
       "678               3                     121              52               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "332        0  43.3              0.282   41             1  \n",
       "106        0  22.4              0.207   27             0  \n",
       "99       220  49.7              0.325   31             1  \n",
       "674        0  35.6              0.587   68             0  \n",
       "678        0  36.0              0.127   25             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.828\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 3s 10ms/step - loss: 0.7284 - accuracy: 0.5556 - val_loss: 0.7423 - val_accuracy: 0.5938\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.5538 - val_loss: 0.7372 - val_accuracy: 0.5885\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.5556 - val_loss: 0.7323 - val_accuracy: 0.5885\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.5642 - val_loss: 0.7275 - val_accuracy: 0.5885\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7093 - accuracy: 0.5694 - val_loss: 0.7228 - val_accuracy: 0.5938\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.5747 - val_loss: 0.7183 - val_accuracy: 0.5938\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.5833 - val_loss: 0.7140 - val_accuracy: 0.5938\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.5868 - val_loss: 0.7097 - val_accuracy: 0.5990\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5903 - val_loss: 0.7057 - val_accuracy: 0.5990\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5920 - val_loss: 0.7017 - val_accuracy: 0.5990\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.6007 - val_loss: 0.6979 - val_accuracy: 0.5990\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6076 - val_loss: 0.6942 - val_accuracy: 0.6042\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6094 - val_loss: 0.6906 - val_accuracy: 0.6094\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6111 - val_loss: 0.6872 - val_accuracy: 0.6094\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6163 - val_loss: 0.6838 - val_accuracy: 0.6094\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6181 - val_loss: 0.6806 - val_accuracy: 0.6094\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6267 - val_loss: 0.6774 - val_accuracy: 0.6146\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6285 - val_loss: 0.6744 - val_accuracy: 0.6146\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6302 - val_loss: 0.6714 - val_accuracy: 0.6146\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6354 - val_loss: 0.6685 - val_accuracy: 0.6146\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6372 - val_loss: 0.6657 - val_accuracy: 0.6146\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6389 - val_loss: 0.6630 - val_accuracy: 0.6146\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6406 - val_loss: 0.6603 - val_accuracy: 0.6146\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6389 - val_loss: 0.6577 - val_accuracy: 0.6146\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6406 - val_loss: 0.6552 - val_accuracy: 0.6146\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6389 - val_loss: 0.6527 - val_accuracy: 0.6146\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6424 - val_loss: 0.6503 - val_accuracy: 0.6094\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6406 - val_loss: 0.6479 - val_accuracy: 0.6146\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6406 - val_loss: 0.6456 - val_accuracy: 0.6146\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6441 - val_loss: 0.6434 - val_accuracy: 0.6146\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6493 - val_loss: 0.6412 - val_accuracy: 0.6250\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6510 - val_loss: 0.6390 - val_accuracy: 0.6198\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6528 - val_loss: 0.6369 - val_accuracy: 0.6198\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6545 - val_loss: 0.6349 - val_accuracy: 0.6198\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6545 - val_loss: 0.6329 - val_accuracy: 0.6250\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6545 - val_loss: 0.6309 - val_accuracy: 0.6302\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6580 - val_loss: 0.6289 - val_accuracy: 0.6302\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6597 - val_loss: 0.6270 - val_accuracy: 0.6302\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.6649 - val_loss: 0.6251 - val_accuracy: 0.6302\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6649 - val_loss: 0.6233 - val_accuracy: 0.6302\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6649 - val_loss: 0.6214 - val_accuracy: 0.6250\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6684 - val_loss: 0.6196 - val_accuracy: 0.6250\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6719 - val_loss: 0.6179 - val_accuracy: 0.6198\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6736 - val_loss: 0.6162 - val_accuracy: 0.6250\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6736 - val_loss: 0.6145 - val_accuracy: 0.6354\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6736 - val_loss: 0.6128 - val_accuracy: 0.6354\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6736 - val_loss: 0.6111 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6788 - val_loss: 0.6094 - val_accuracy: 0.6510\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.6840 - val_loss: 0.6078 - val_accuracy: 0.6458\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.6875 - val_loss: 0.6062 - val_accuracy: 0.6458\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6875 - val_loss: 0.6047 - val_accuracy: 0.6562\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6927 - val_loss: 0.6031 - val_accuracy: 0.6562\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6927 - val_loss: 0.6016 - val_accuracy: 0.6510\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6910 - val_loss: 0.6001 - val_accuracy: 0.6510\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.6910 - val_loss: 0.5986 - val_accuracy: 0.6562\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.6927 - val_loss: 0.5971 - val_accuracy: 0.6615\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6962 - val_loss: 0.5957 - val_accuracy: 0.6667\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.6979 - val_loss: 0.5943 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7014 - val_loss: 0.5929 - val_accuracy: 0.6719\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7083 - val_loss: 0.5915 - val_accuracy: 0.6719\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7101 - val_loss: 0.5902 - val_accuracy: 0.6719\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7135 - val_loss: 0.5889 - val_accuracy: 0.6719\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7153 - val_loss: 0.5876 - val_accuracy: 0.6719\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7153 - val_loss: 0.5863 - val_accuracy: 0.6719\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7135 - val_loss: 0.5850 - val_accuracy: 0.6771\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7118 - val_loss: 0.5837 - val_accuracy: 0.6823\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7222 - val_loss: 0.5825 - val_accuracy: 0.6875\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7240 - val_loss: 0.5813 - val_accuracy: 0.6875\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7257 - val_loss: 0.5802 - val_accuracy: 0.6875\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7292 - val_loss: 0.5791 - val_accuracy: 0.6823\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7326 - val_loss: 0.5780 - val_accuracy: 0.6875\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7326 - val_loss: 0.5770 - val_accuracy: 0.6875\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7344 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7378 - val_loss: 0.5749 - val_accuracy: 0.6927\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7413 - val_loss: 0.5740 - val_accuracy: 0.6875\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7431 - val_loss: 0.5730 - val_accuracy: 0.6875\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7413 - val_loss: 0.5720 - val_accuracy: 0.6875\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7413 - val_loss: 0.5711 - val_accuracy: 0.6875\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7448 - val_loss: 0.5701 - val_accuracy: 0.6875\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7483 - val_loss: 0.5692 - val_accuracy: 0.6875\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7483 - val_loss: 0.5683 - val_accuracy: 0.6875\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7483 - val_loss: 0.5674 - val_accuracy: 0.6875\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7483 - val_loss: 0.5665 - val_accuracy: 0.6875\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7465 - val_loss: 0.5657 - val_accuracy: 0.6927\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7483 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7483 - val_loss: 0.5640 - val_accuracy: 0.6927\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.6927\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7517 - val_loss: 0.5623 - val_accuracy: 0.6979\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7517 - val_loss: 0.5615 - val_accuracy: 0.6979\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7483 - val_loss: 0.5607 - val_accuracy: 0.7031\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7500 - val_loss: 0.5600 - val_accuracy: 0.7083\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7465 - val_loss: 0.5592 - val_accuracy: 0.7083\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7500 - val_loss: 0.5584 - val_accuracy: 0.7083\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7500 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7500 - val_loss: 0.5570 - val_accuracy: 0.7135\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7500 - val_loss: 0.5562 - val_accuracy: 0.7135\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7517 - val_loss: 0.5555 - val_accuracy: 0.7135\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7517 - val_loss: 0.5548 - val_accuracy: 0.7135\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7535 - val_loss: 0.5542 - val_accuracy: 0.7135\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7535 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7569 - val_loss: 0.5529 - val_accuracy: 0.7240\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7569 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7587 - val_loss: 0.5517 - val_accuracy: 0.7240\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7587 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7569 - val_loss: 0.5505 - val_accuracy: 0.7240\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7569 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7569 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7587 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7604 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7604 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7604 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7604 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7656 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7674 - val_loss: 0.5457 - val_accuracy: 0.7344\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7656 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7691 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7691 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7674 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7691 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7691 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7691 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7674 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7674 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7656 - val_loss: 0.5411 - val_accuracy: 0.7552\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7656 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7639 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7552\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7622 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7622 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7656 - val_loss: 0.5377 - val_accuracy: 0.7604\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7674 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7674 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7674 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5358 - val_accuracy: 0.7656\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7708 - val_loss: 0.5355 - val_accuracy: 0.7656\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7691 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7656 - val_loss: 0.5344 - val_accuracy: 0.7708\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.5330 - val_accuracy: 0.7708\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7656 - val_loss: 0.5327 - val_accuracy: 0.7708\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7674 - val_loss: 0.5324 - val_accuracy: 0.7708\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5321 - val_accuracy: 0.7760\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.5318 - val_accuracy: 0.7760\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7674 - val_loss: 0.5314 - val_accuracy: 0.7760\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7674 - val_loss: 0.5311 - val_accuracy: 0.7760\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.5309 - val_accuracy: 0.7760\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7656 - val_loss: 0.5306 - val_accuracy: 0.7708\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7656 - val_loss: 0.5303 - val_accuracy: 0.7708\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7639 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7639 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7604 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7622 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7604 - val_loss: 0.5287 - val_accuracy: 0.7708\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7604 - val_loss: 0.5285 - val_accuracy: 0.7708\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7604 - val_loss: 0.5283 - val_accuracy: 0.7708\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7604 - val_loss: 0.5280 - val_accuracy: 0.7708\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7604 - val_loss: 0.5278 - val_accuracy: 0.7708\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7622 - val_loss: 0.5276 - val_accuracy: 0.7708\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7622 - val_loss: 0.5274 - val_accuracy: 0.7708\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7622 - val_loss: 0.5272 - val_accuracy: 0.7708\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7622 - val_loss: 0.5270 - val_accuracy: 0.7708\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7622 - val_loss: 0.5268 - val_accuracy: 0.7708\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7622 - val_loss: 0.5266 - val_accuracy: 0.7708\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7639 - val_loss: 0.5264 - val_accuracy: 0.7708\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.5262 - val_accuracy: 0.7708\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7656 - val_loss: 0.5260 - val_accuracy: 0.7708\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7708\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7674 - val_loss: 0.5246 - val_accuracy: 0.7708\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7674 - val_loss: 0.5245 - val_accuracy: 0.7708\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7674 - val_loss: 0.5243 - val_accuracy: 0.7708\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7708\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7708\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7708\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.5238 - val_accuracy: 0.7708\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7708 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7708 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7708 - val_loss: 0.5226 - val_accuracy: 0.7708\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7691 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "#y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "#y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")\n",
    "\n",
    "#O mÃ©todo \"predict_classes\" nÃ£o funciona nas versÃµes do Keras superior a 2.5 \n",
    "\n",
    "# A indicaÃ§Ã£o da correÃ§Ã£o se encontra em https://keras.rstudio.com/reference/predict_proba.html#details. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61289346],\n",
       "       [0.82188576],\n",
       "       [0.25061363],\n",
       "       [0.27771303],\n",
       "       [0.18991533],\n",
       "       [0.52391744],\n",
       "       [0.06130368],\n",
       "       [0.3522847 ],\n",
       "       [0.7077393 ],\n",
       "       [0.17696917]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.800\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e228fbeb50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAofUlEQVR4nO3deZxU5Z3v8c+PapaouARI4qWRZaJOlN0WUirQCKLigusN6EQZHAkYVCQ6xskigRCX8V6VjIqAaHQciUZB3EBBkDj2jYAigluQRTskKp2rYAJCdz/zx6nqPl1UVZ/qrr2+79eLV9c5dU6dp04Vv/PU71mOOecQEZHi1SbXBRARkcxSoBcRKXIK9CIiRU6BXkSkyCnQi4gUubJcFyCezp07ux49euS6GCIiBWPdunU7nXNd4j2Xl4G+R48erF27NtfFEBEpGGa2PdFzgVI3ZnaGmb1vZpvN7Mdxnr/BzNZH/m00szoz+3rkuW1m9nbkOUVvEZEsa7ZGb2Yh4B7gNKAaWGNmS5xz70S3cc79O/Dvke3PAa5zzv3V9zLDnXM701pyEREJJEiNfhCw2Tm3xTm3D1gIjEmy/TjgsXQUTkREWi9Ijr4r8LFvuRoYHG9DMzsIOAOY4lvtgBfNzAH3O+fmJth3IjAR4KijjgpQLBFprf3791NdXc3evXtzXRQJqEOHDpSXl9O2bdvA+wQJ9BZnXaIJcs4B/jsmbXOyc26HmX0DeMnM3nPOrT7gBb0LwFyAiooKTcAjkgXV1dV07NiRHj16YBbvv7rkE+ccNTU1VFdX07Nnz8D7BUndVAPdfMvlwI4E244lJm3jnNsR+fspsAgvFSQieWDv3r106tRJQb5AmBmdOnVK+RdYkEC/BjjazHqaWTu8YL4kTgEOA4YBT/vWHWxmHaOPgVHAxpRKmIKqKrjlFu+viASjIF9YWvJ5NZu6cc7VmtkUYBkQAhY45zaZ2aTI83Mim54PvOic+5tv928CiyIFKwP+yzm3NOVSBrBqFYwaBXV10L49rFgB4XAmjiQiUlgCDZhyzj0PPB+zbk7M8kPAQzHrtgD9WlXCgF59Ffbv9x7v2+cFfgV6kfxWU1PDiBEjAPjLX/5CKBSiSxdvcOfrr79Ou3btEu67du1aHn74YWbPnh34eNHBmJ07d25dwQtMXo6MbYkRI+AXv4DaWmjbFiorc10iEWlOp06dWL9+PQDTp0/nkEMO4frrr294vra2lrKy+GGqoqKCioqKbBSz4BXNpGbhMDz1FJjB0UfnujQiRSzDjWHjx49n2rRpDB8+nBtvvJHXX3+dk046iQEDBnDSSSfx/vvvA7Bq1SrOPvtswLtITJgwgcrKSnr16pVSLX/79u2MGDGCvn37MmLECD766CMAnnjiCXr37k2/fv0YOnQoAJs2bWLQoEH079+fvn378sc//jHN7z4ziqZGD9C5M7RpA2+/7dXwlacXScHUqRCpXSf0xRewYQPU13v/2fr2hcMOS7x9//5w110pF+WDDz5g+fLlhEIhdu3axerVqykrK2P58uX827/9G08++eQB+7z33nusXLmS3bt3c+yxxzJ58uRAfc2nTJnCZZddxuWXX86CBQu45pprWLx4MTNmzGDZsmV07dqVzz//HIA5c+Zw7bXXcumll7Jv3z7q6upSfm+5UDQ1evDy8tFb4H71lbcsImn0xRdekAfv7xdfZOQwF198MaFQKHLIL7j44ovp3bs31113HZs2bYq7z1lnnUX79u3p3Lkz3/jGN/jkk08CHauqqopLLrkEgO9///u8+uqrAJx88smMHz+eefPmNQT0cDjMr371K2677Ta2b9/O1772tda+1awoqhp9ZaXX42bPHi/gDxuW6xKJFJAgNe+qKu/n8r590K4dPPpoRn42H3zwwQ2Pf/aznzF8+HAWLVrEtm3bqEzQANe+ffuGx6FQiNra2hYdO9p9cc6cOfzhD3/gueeeo3///qxfv55LLrmEwYMH89xzz3H66aczf/58Tj311BYdJ5uKqkYfDnvpmvPP9wL9b36jPvUiaRX9TzZzZtZyo1988QVdu3YF4KGHHkr765900kksXLgQgEcffZRTTjkFgA8//JDBgwczY8YMOnfuzMcff8yWLVvo1asX11xzDeeeey4bNmxIe3kyoagCPXjfu6uv9h7PnetVPhTsRdIoHIabbspaA9i//uu/ctNNN3HyySenJSfet29fysvLKS8vZ9q0acyePZsHH3yQvn378sgjj3D33XcDcMMNN9CnTx969+7N0KFD6devH7/97W/p3bs3/fv357333uOyyy5rdXmywZzLv2llKioqXItuPFJVBatWcctHl/CT+7vjHIRCXuXjppvSX06RQvfuu+/yne98J9fFkBTF+9zMbJ1zLm5/0+LJ0a9eDSNHQl0dlWXLaN/2Zfbua4Nz0KlTrgsnIpI7xZO6eeUVb2hsfT3hule5e/RSzLyOAVOnKn0jIqWreAL9yJEQHUHXti013zqe6Nw/e/eqq6WIlK7iCfThMDz5ZMPQ2MoBu4j2tnIOtm5VrV5ESlPxBHqALl0ahsaGpw5mxV1vc+aZ3lMPPKAeOCJSmoor0McMjQ3XPEukSyz19Y2zWoqIlJLiCvTRobHgRfbt2xne+W2iM52GQprVUiSfVFZWsmzZsibr7rrrLq666qqk+0S7X48ePbphHhq/6dOnc8cddyQ99uLFi3nnnXcaln/+85+zfPnyFEofn3+ytXxRXIE+OmovMr818+YRnjqY5Xe9TceO3txLeThsQKRkjRs3rmFUatTChQsZN25coP2ff/55Dj/88BYdOzbQz5gxg5EjR7botfJdcQV68IJ9tNoeydeUbXiTvXvhs8/g1FOVpxdpjXTOUnzRRRfx7LPP8tVXXwGwbds2duzYwSmnnMLkyZOpqKjg+OOP5+abb467f48ePdi5cycAs2bN4thjj2XkyJENUxkDzJs3jxNPPJF+/fpx4YUX8ve//53XXnuNJUuWcMMNN9C/f38+/PBDxo8fz+9+9zsAVqxYwYABA+jTpw8TJkxoKF+PHj24+eabGThwIH369OG9994L/F4fe+yxhpG2N954IwB1dXWMHz+e3r1706dPH+68804AZs+ezXHHHUffvn0ZO3Zsimf1QMUzYMpvxAiYMcPrV19WxiqGNUy4F53VUtMXizSVi1mKO3XqxKBBg1i6dCljxoxh4cKFfO9738PMmDVrFl//+tepq6tjxIgRbNiwgb59+8Z9nXXr1rFw4ULefPNNamtrGThwICeccAIAF1xwAVdeeSUAP/3pT3nggQe4+uqrOffcczn77LO56KKLmrzW3r17GT9+PCtWrOCYY47hsssu47777mPq1KkAdO7cmTfeeIN7772XO+64g/nz5yc/acCOHTu48cYbWbduHUcccQSjRo1i8eLFdOvWjT/96U9s3OjdSjuahrr11lvZunUr7du3j5uaSlXx1ejBi+LPPuv1q+/WjcoBu2jXjoZ+9WvWqFYv0hKZmKXYn77xp20ef/xxBg4cyIABA9i0aVOTNEus3//+95x//vkcdNBBHHrooZx77rkNz23cuJEhQ4bQp08fHn300YTTHEe9//779OzZk2OOOQaAyy+/nNWrVzc8f8EFFwBwwgknsG3btkDvcc2aNVRWVtKlSxfKysq49NJLWb16Nb169WLLli1cffXVLF26lEMPPRTw5uO59NJL+c///M+Ed9hKRXHW6AE6dvT+bt5M+NpBrLj7deb/oQ8LFsCiRbB0qW5MIuKXq1mKzzvvPKZNm8Ybb7zBnj17GDhwIFu3buWOO+5gzZo1HHHEEYwfP569e/cmfZ3o9MKxxo8fz+LFi+nXrx8PPfQQq5rpetfc/F/R6ZBTmQo50WseccQRvPXWWyxbtox77rmHxx9/nAULFvDcc8+xevVqlixZwsyZM9m0aVOrAn5x1ughblfLb3+7sVavrpYiqcvELMWHHHIIlZWVTJgwoaE2v2vXLg4++GAOO+wwPvnkE1544YWkrzF06FAWLVrEnj172L17N88880zDc7t37+bII49k//79PProow3rO3bsyO7duw94rX/8x39k27ZtbN68GYBHHnmEYa28ucXgwYN55ZVX2LlzJ3V1dTz22GMMGzaMnTt3Ul9fz4UXXsjMmTN54403qK+v5+OPP2b48OHcfvvtfP7553z55ZetOn7x1ugrK70qx969XsD/4AMqw2/ToUMf9uzxfnZqsjOR1IXD6f8lPG7cOC644IKGFE6/fv0YMGAAxx9/PL169eLkk09Ouv/AgQP53ve+R//+/enevTtDhgxpeG7mzJkMHjyY7t2706dPn4bgPnbsWK688kpmz57d0AgL0KFDBx588EEuvvhiamtrOfHEE5k0aVJK72fFihWUl5c3LD/xxBPccsstDB8+HOcco0ePZsyYMbz11lv88z//M/WRfNgtt9xCXV0d//RP/8QXX3yBc47rrruuxT2LooprmuJYVVVw553wxBNeVb5DB+Ze/TaT7/gH6uu9LvcrVyp9I6VL0xQXplSnKS7e1A14EXzAAO+xc7BvHzXrP25I3+i+siJSCoo70EPT0bLOUdn/c9q187qGgVfpVw8cESlmxR/ow2GYPZvo5PThX1/CirveZsIE7+lnntFkZ1La8jF9K4m15PMq/kAPUFODf3L6cM2z9OqFUjhS8jp06EBNTY2CfYFwzlFTU0OHDh1S2i9QrxszOwO4GwgB851zt8Y8fwNwqe81vwN0cc79tbl9syKavtmzx8vVb9lC5YlNe+Bs2+bV6tUwK6WkvLyc6upqPvvss1wXRQLq0KFDkx49QTTb68bMQsAHwGlANbAGGOeciztMzczOAa5zzp2a6r5Raet141dVBbfeCkuWNPTAqbrrD8xc3IcXXmhYpUFUIlKQWtvrZhCw2Tm3xTm3D1gIjEmy/TjgsRbumznhMHz3u97jSA8c/3z1znld7h9+OCelExHJmCCBvivwsW+5OrLuAGZ2EHAG8GQL9p1oZmvNbG3GfkbG9MChUyeGD4e2bRtXPfigGmZFpLgECfTxJpBIlO85B/hv59xfU93XOTfXOVfhnKvo0qVLgGK1QEwPHKZOJUwVV1zRuEltrRpmRaS4BAn01UA333I5sCPBtmNpTNukum92+HvgRLrbXHaZl58Hr1b/0Ueq1YtI8QgS6NcAR5tZTzNrhxfMl8RuZGaHAcOAp1PdN6tibzf44YeEqeLll6Giwls1d6761otI8Wg20DvnaoEpwDLgXeBx59wmM5tkZv6Zfs4HXnTO/a25fdP5BlIWnX7vvPO85QULYMQIwlRxzjneKt1IXESKSaABU865551zxzjn/sE5Nyuybo5zbo5vm4eccwfc8yrevjkXDsOgQd7jSA8cVq3itNNouJF4pK1WRKTglcbI2Hj8KRyAjz4iTBW//nVjW+211yp9IyKFr3QDfTjszVH87W9DXR3MmwcjRlDz5nb/bAlMn65gLyKFrXQDPXjBfkxk/FZdHezbRyWvNKnov/SSGmZFpLCVdqAHuPBC7ybiEeEBe1mxwgvuoBGzIlL4FOjDYbj9du9xXV3DIKqZMzViVkSKgwI9eFX2mEFU4TAaMSsiRUGBHrweONGhsfX1sHUrVFU1GTHrn8pYRKSQKNBD4yCqM8/0lufPbxhE9fLLXr7euYaOOQr2IlJQFOijwmHizVkcDsOppx6wWkSkYCjQ+w0f3nRobKQFNsFqEZGCoEDvFw7TcNdwaGiBjV391VcaSCUihUOBPlZsC+z27Q0Ns1/7WuNmGkglIoVCgT5WOAwvvwzDhnl5msicxWGqWLFC+XoRKTwK9PGEwzBqlPc4pmH2l7/UQCoRKSwK9IkkuJls7ECqffuUrxeR/KZAn0hsRN+/v2ForD9f7xwsX658vYjkLwX6ZPwR3Tc0Njq+asiQxqd0RyoRyVcK9MlEI/ppp3nLvqGx4TDcdpvuSCUi+U+BvjnhsDcXDhzQ1SYchl//Gtq08Wr1V1+t9I2I5B8F+iCSDI2tqWmc+HLfPrj+egV7EckvCvRBxA6N9XW1qaz0rgFtImfytddg6FCv+72ISD5QoA8qQVeb6ECqkSMbN62thSlTVLMXkfygQB9Ukq424bBXwffdkZD9+9W/XkTygwJ9KqJdbfwDqSJdbcJhuOeexqdA8+GISH5QoE9VOAz/8R9eC2x9PVx7bUMknzgRXnmlMY3jnGa6FJHcU6BviZqaxtbXvXvh5z9viOThMMyY0XQCTI2cFZFcUqBviWhXm2i/yphIHp0A86STvKfr6zXTpYjkTqBAb2ZnmNn7ZrbZzH6cYJtKM1tvZpvM7BXf+m1m9nbkubXpKnhOxY6YhQMieTgMd9zR2ECrmS5FJFeaDfRmFgLuAc4EjgPGmdlxMdscDtwLnOucOx64OOZlhjvn+jvnKtJS6nwQ7WqT5B6D4TD8y7807qJ8vYjkQpAa/SBgs3Nui3NuH7AQGBOzzSXAU865jwCcc5+mt5h5KjqQKprCiRPJY+9M9eKLGlAlItkVJNB3BT72LVdH1vkdAxxhZqvMbJ2ZXeZ7zgEvRtZPTHQQM5toZmvNbO1nn30WtPy557/1IBzQpzKa5YnexwQ0oEpEsitIoLc461zMchlwAnAWcDrwMzM7JvLcyc65gXipnx+a2dB4B3HOzXXOVTjnKrp06RKs9PkgNpLHucegBlSJSC4FCfTVQDffcjmwI842S51zf3PO7QRWA/0AnHM7In8/BRbhpYKKS8B8/T33NA32GlAlItkQJNCvAY42s55m1g4YCyyJ2eZpYIiZlZnZQcBg4F0zO9jMOgKY2cHAKGBj+oqfRwLk6ydOhNWrE856LCKSEc0GeudcLTAFWAa8CzzunNtkZpPMbFJkm3eBpcAG4HVgvnNuI/BN4FUzeyuy/jnn3NLMvJU80Ey+Hrzrwa9+1bTyP38+TJ6smr2IZIY5F5tuz72Kigq3dm2BdrmvqvJq8i++6C2bef3tp0/3onzE5Mlw//1eoI9u1qGDl+73bSYiEoiZrUvUhV0jY9Mtmq9v5u7h0cp/NNOjNI6IZIoCfSZEe+IkmQMhuskPftB09KzSOCKSbkrdZFJVlTc6qrbWW27fHlauPCA3ozSOiLSWUje5EjsHgu8WhH5K44hIJinQZ1rsLQgT9MSJl8aZN09pHBFpPQX6TItG8eHDveUE1fVwGO67z/sBEK3Z19V5KR0NqhKR1lCgz4ZwGGbNSjpyNkppHBFJNwX6bIk3cvbmmw8I9krjiEi6KdBnU2x1/aWX4s5ZnCiNM2eOpjgWkdQp0GdTvDtTJZmzOPa60MzmIiJxKdBnW7w5i2tr43a79KdxQqHG9fv3N7kfuYhIUgr0uRA7Z3GCaRKim953H9x7L7Rt27h++XKlcUQkGAX6XInOWTxkiLccZ5qE2M1feeXAO1VddZUaaUUkOU2BkGtVVTBsmJePgYTTJPg398+qAJoyQUQ0BUJ+C4fhiiuadrv82c8SVtGjWZ+2bQ/sa69bE4pIPAr0+SC2e82KFUkT8NE0zg9+0HQM1osvKm8vIgdSoM8HKXa7jO5y332wapXXhuvfTXl7EfFToM8X8bpd7t/fbD4mHIaZM5vupsFVIuKnQJ9P/An4qDizXQbZDTS4SkQ8CvT5JpqAHznSWw44q1l0t0mTDhxcpUZakdKmQJ+PwmGYMaNpS2uAWc38g6v8qRw10oqUNgX6fBU722UKk9NHx2LFtu2qkVakNCnQ57NWTE4fDsMvfqFGWhFRoM9viSannz8/UNU83uAqUO1epNRoCoRCMXmyl7qJfl4pzHtQVeX9CJg3z6vVR2nqBJHioSkQikEr0zjxZsDUbQpFSoMCfaFIlMZZsCBw/sXfBdP/EnPnei+rNI5IcQoU6M3sDDN738w2m9mPE2xTaWbrzWyTmb2Syr4SULx7DO7bB9dfHzhKx3uJ+nov2KuRVqQ4NRvozSwE3AOcCRwHjDOz42K2ORy4FzjXOXc8cHHQfaUFommcNpGP77XXoLIypdbVRLcpnDzZq/Grdi9SPILU6AcBm51zW5xz+4CFwJiYbS4BnnLOfQTgnPs0hX0lVdE0zsiRjcF+376U+k4muk1hfb3X5qvavUjxCBLouwIf+5arI+v8jgGOMLNVZrbOzC5LYV8AzGyima01s7WfffZZsNKXsugkaO3bt/ju4bGNtPFq9+qCKVL4ggR6i7Mutk9mGXACcBZwOvAzMzsm4L7eSufmOucqnHMVXbp0CVAsSXr38BQmuPHPbx9bu9cAK5HCFyTQVwPdfMvlwI442yx1zv3NObcTWA30C7ivtEaaJrhR7V6keAUJ9GuAo82sp5m1A8YCS2K2eRoYYmZlZnYQMBh4N+C+kg7RCW5OPbVxXQvmKW6udp9im6+I5IFmA71zrhaYAizDC96PO+c2mdkkM5sU2eZdYCmwAXgdmO+c25ho38y8FSEchl/+MuWbl8R7mUS1+xTbfEUkD2gKhGI0dy788IdejT6qrMyb+GbixJReKjp9woMPekHe/3UJheDKK72umppCQSS3NAVCqYmmcUaNalzXwpnMorX7lSsPTOdoNkyRwqAafTGrqvKisL9m38qZzObO9dL+tbWq3YvkE9XoS1W8m8m2ciazRI21qt2L5C8F+mKXaCazALcmTERdMUUKiwJ9KYg3k1kaquAaaCVSGBToS0mimcxS7Gvv11ztftIkOOcc1fBFckmBvpQkmzLhpz9tVSROVLt3Dp591qvhDxumgC+SCwr0pSbR7aZefrnVuZZktXvwridK6YhknwJ9qYpWwWP72qehJdVfu/dfS2IPo3nvRbJD/ehLXby+9tDikbTxXv7hh+Evf4Fnnml6c3Lw0jw/+hEcfrg3j4764Iu0TLJ+9Ar0kngUVFmZN8I2TdE30WH8h0vDtUWkJGnAlCSXqCW1thZuuilt+ZVEh/EfbvJkb7u5c+GWW5TaEUkH1eilqWi1e//+xnWhkNfCmsaqdnO1e/Aac0Mh1fJFglDqRlJTVeVNbfzSS41R2MyLtpdfnrZUTlUVrFoFn38Od96ZOOiHQl5f/G99S3PpiCSiQC+pS9RI264dTJiQ9ojrnw55/35vdG08bdvCFVco4IvEUqCXlkmWX8lQy2nQWn5ZGUybpt46IlEK9NJyObzzSPTQDzzQtMnAT3l8EY8CvbReNOrOm9e0M3wr57dP5dCJ+uIDtGnj5fGPPFJpHSlNCvSSPvFuU2jm9Zm8776sHL653jplZXD22Wq8ldKiQC/pFa92n8VbTAXN44Mab6V0KNBLZkyeDPfff+Bo2iwmzIPk8aPFUuOtFDMFesmMqioYMcK7NWGObyDrz+M/95yCvpQeBXrJnESNtJCzyWuCNN6C17TQti2MHq18vhQ+BXrJvEStpDmo3QcpVjxt28JZZynoS2FSoJfsyMPafbRYQRtvoxT0pdAo0Et25WntHhqDfqdO8OabzTfigoK+FAYFesm+PK3dx0qlERcU9CV/tTrQm9kZwN1ACJjvnLs15vlK4Glga2TVU865GZHntgG7gTqgNlFB/BToi0ge1+5jpRr0NTBL8kmrAr2ZhYAPgNOAamANMM45945vm0rgeufc2XH23wZUOOd2Bi2wAn2RKZDavV+qQT8UgjPOgG7dYMAAqKlR103JrmSBvizA/oOAzc65LZEXWwiMAd5JupdIVDjs/Rsw4MDafW0tXHWVlzDPo2pxtMgQLOjX1XnP+am/vuSLIDX6i4AznHP/Eln+PjDYOTfFt00l8CRejX8HXu1+U+S5rcD/Bxxwv3NuboLjTAQmAhx11FEnbN++vVVvTPJUAdbu/VKt6YPXX7+szOuvf+SRqvFLZrQ2dXMxcHpMoB/knLvat82hQL1z7kszGw3c7Zw7OvLc/3LO7TCzbwAvAVc751YnO6ZSNyUgUe6+TRsvd5/GO1llSkuCvl+0xr9rl7ecRz9opAC1NtCHgenOudMjyzcBOOduSbLPNuLk5c1sOvClc+6OZMdUoC8RyWr3BTYbWfStABx6aNP++mbN99uHpj16VOuXVLU20JfhNcaOAP6E1xh7STQ1E9nmW8AnzjlnZoOA3wHdgYOANs653WZ2MF6NfoZzbmmyYyrQl5jm7mRVgInulvTXjxW9qYpq/RJEOrpXjgbuwuteucA5N8vMJgE45+aY2RRgMlAL7AGmOedeM7NewKLIy5QB/+Wcm9Xc8RToS1CyO1lBwd9KKlmNPxX+Lp2q9YufBkxJ4UiWzoG87H/fErE1/pbm+aHpj55OnRT8S5UCvRSe5mYjK4AeOqlKV60f1NBbihTopTDFzkYWW90tktp9Iums9YdCMGoUdO/upXzefNNbX6SnriQp0Evha67/fQE22LZEOnr3+JWVwZlnQteuugAUOgV6KR7JUjoF3mDbEv5af01NalMxJ1NW5nX1jA7w0gUg/ynQS3EpkQbblkpnyidWWRlMmAAnnNAY/NX7Jz8o0EtxKsEG25byp3yiNfR0XgDi9fnXBSC7FOileDV3+6g2beCcc7wcRInW8JPJ9AUAvAvANdfAnj1NjwP6SNJJgV5KQ3MpnQKbViGXEl0AXnjBuwDU16fnOKEQnHoq9OwZPx2kcQHBKdBLaVFKJ2Ni8//Q+j7/zUmUFlIbQVMK9FJ6olXSRJPMtGnjBXrV7tMiFxeAWGVl8MMfwt693sUh9mJQ7OkiBXopXf65hJ95Jv4smdGJ4os1AuRQvAtA0LaAlowLCCIUgqFDobzc+7g//zx++WIf5/vXQ4FeBJpP6SiHn3Xx2gKij9M5LiAdou0J5eXw3e82f2HI9kVCgV4kqrlZMkE5/DyT7FcBZD9F1BKhkDfraN++8OGH0K4dDBoEGzZ4z6fjoqBALxKruRy+mfc/s2tX1fALQHMXg2TpokyliFqqfXtYuTL1r5wCvUgizeXwQSmdIhObLop240z1ApEpZjBrFtx0U6r7KdCLNC9It8wSmTxNDpSsPaG5i0Qq4w9UoxfJtOZSOlHK40sKgqaWQDl6kewJktIx86Z4LC9XWkdyToFepDWaS+lA05u5KuhLDijQi7RWc5On+anxVnJAgV4knYLm8UMh+NGP1HgrWaFAL5IJ/jx+c2P5o1MtKLUjGaJAL5JpQRpvo9q29RpxFfQljRToRbIptvE22dBL5fMlTRToRbIttuN0kH75GowlraBAL5JrQfP5oKAvLaJAL5JPUsnnK+hLQK0O9GZ2BnA3EALmO+dujXm+Enga2BpZ9ZRzbkaQfeNRoJeSEWQwVpSCviSRLNCXBdg5BNwDnAZUA2vMbIlz7p2YTX/vnDu7hfuKlKaJE6FPn2CDsWpr4fbbvccK+pKCZgM9MAjY7JzbAmBmC4ExQJBg3Zp9RUpDONwYqM87T0Ff0i5IoO8KfOxbrgYGx9kubGZvATuA651zm1LYFzObCEwEOOqoowIUS6QItTbo+++BG51sXcG/5AUJ9BZnXey37Q2gu3PuSzMbDSwGjg64r7fSubnAXPBy9AHKJVLcWhL09++Hp59uXDbzpmJQjb+kBQn01UA333I5Xq29gXNul+/x82Z2r5l1DrKviAQQJOjHG5jlnNI8EijQrwGONrOewJ+AscAl/g3M7FvAJ845Z2aDgDZADfB5c/uKSIriBf2gA7PiBf1dkXqaRucWraDdK0cDd+F1kVzgnJtlZpMAnHNzzGwKMBmoBfYA05xzryXat7njqXulSAv573d36KHNT6nspzl4CpoGTImUqlTm0fcLhbwbqahRt2Ao0ItIy4M+qFG3ACjQi0hTsZOuBZmDJ8rMy++rG2deadXIWBEpQv4G3aigE685d2A3TlDjbh5TjV5EDpSsUTfZ/Pp+/humq9afcUrdiEjrpDq/fiKq9WeMAr2IpFdrunH6qdafNgr0IpJZrWncjeUfvdupk4J/QAr0IpJ96ar1g9e189pr4e9/95ZV+z+AAr2I5F46a/1RsTn/Er4AKNCLSH5KR++eeErwAqBALyKFwV/rr6lp2SjeZMrKYOpU+PJLb7mILgAK9CJSuGJTPtD6nL9fdKTviBHQvTsMHNh4nAK6ECjQi0jxyfQFwC9eKih6zDwZC6BALyKlI9ULQGvaAsC7CIwaBd265fTXgAK9iEi8C0C0Zt7Skb5BhEIwZQp885sHHjuNFwIFehGRZPy9f/xpmUylgvzKyrwLwd693nILU0EK9CIiLZXsl0A6xgLEat8eVq5MOdhrmmIRkZaKN6WzX9BfA0HbAvbt8y4saczrK9CLiLRGsguB/+btNTXBGojbtfPy9mmkQC8ikinN/RrwXwgy2F1TgV5EJFeauxCkSZuMH0FERHJKgV5EpMgp0IuIFDkFehGRIqdALyJS5BToRUSKXF5OgWBmnwHbW7h7Z2BnGouTLipX6vK1bCpXalSu1LWkbN2dc13iPZGXgb41zGxtovkecknlSl2+lk3lSo3Klbp0l02pGxGRIqdALyJS5Iox0M/NdQESULlSl69lU7lSo3KlLq1lK7ocvYiINFWMNXoREfFRoBcRKXJFE+jN7Awze9/MNpvZj3NYjm5mttLM3jWzTWZ2bWT9dDP7k5mtj/wbnaPybTOztyNlWBtZ93Uze8nM/hj5e0SWy3Ss77ysN7NdZjY1F+fMzBaY2admttG3LuH5MbObIt+5983s9ByU7d/N7D0z22Bmi8zs8Mj6Hma2x3fu5mS5XAk/u2ydswTl+q2vTNvMbH1kfTbPV6IYkbnvmXOu4P8BIeBDoBfQDngLOC5HZTkSGBh53BH4ADgOmA5cnwfnahvQOWbd7cCPI49/DNyW48/yL0D3XJwzYCgwENjY3PmJfK5vAe2BnpHvYCjLZRsFlEUe3+YrWw//djk4Z3E/u2yes3jlinn+/wA/z8H5ShQjMvY9K5Ya/SBgs3Nui3NuH7AQGJOLgjjn/uyceyPyeDfwLtA1F2VJwRjgN5HHvwHOy11RGAF86Jxr6cjoVnHOrQb+GrM60fkZAyx0zn3lnNsKbMb7LmatbM65F51ztZHF/weUZ+r4qZQriayds2TlMjMD/jfwWCaOnUySGJGx71mxBPquwMe+5WryILiaWQ9gAPCHyKopkZ/YC7KdHvFxwItmts7MJkbWfdM592fwvoTAN3JUNoCxNP3Plw/nLNH5ybfv3QTgBd9yTzN708xeMbMhOShPvM8uX87ZEOAT59wffeuyfr5iYkTGvmfFEugtzrqc9hs1s0OAJ4GpzrldwH3APwD9gT/j/WzMhZOdcwOBM4EfmtnQHJXjAGbWDjgXeCKyKl/OWSJ5870zs58AtcCjkVV/Bo5yzg0ApgH/ZWaHZrFIiT67fDln42haocj6+YoTIxJuGmddSuesWAJ9NdDNt1wO7MhRWTCztngf4KPOuacAnHOfOOfqnHP1wDwy+BM/GefcjsjfT4FFkXJ8YmZHRsp+JPBpLsqGd/F5wzn3SaSMeXHOSHx+8uJ7Z2aXA2cDl7pIUjfyM78m8ngdXl73mGyVKclnl/NzZmZlwAXAb6Prsn2+4sUIMvg9K5ZAvwY42sx6RmqFY4EluShIJPf3APCuc+7/+tYf6dvsfGBj7L5ZKNvBZtYx+hivIW8j3rm6PLLZ5cDT2S5bRJNaVj6cs4hE52cJMNbM2ptZT+Bo4PVsFszMzgBuBM51zv3dt76LmYUij3tFyrYli+VK9Nnl/JwBI4H3nHPV0RXZPF+JYgSZ/J5lo5U5Sy3Zo/Farz8EfpLDcpyC97NqA7A+8m808AjwdmT9EuDIHJStF17r/VvApuh5AjoBK4A/Rv5+PQdlOwioAQ7zrcv6OcO70PwZ2I9Xk7oi2fkBfhL5zr0PnJmDsm3Gy99Gv2tzItteGPmM3wLeAM7JcrkSfnbZOmfxyhVZ/xAwKWbbbJ6vRDEiY98zTYEgIlLkiiV1IyIiCSjQi4gUOQV6EZEip0AvIlLkFOhFRIqcAr2ISJFToBcRKXL/A64h7Ps4jYmPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7708\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7708\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7691 - val_loss: 0.5218 - val_accuracy: 0.7708\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7691 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7691 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7656 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7639 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7639 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7639 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7656 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7656 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7656 - val_loss: 0.5203 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.5200 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7656\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7656\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.5196 - val_accuracy: 0.7656\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7656\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7656\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.5193 - val_accuracy: 0.7656\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.5193 - val_accuracy: 0.7656\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.5191 - val_accuracy: 0.7656\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7708\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7708\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7726 - val_loss: 0.5179 - val_accuracy: 0.7708\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7726 - val_loss: 0.5179 - val_accuracy: 0.7708\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5178 - val_accuracy: 0.7708\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.5178 - val_accuracy: 0.7708\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.5177 - val_accuracy: 0.7708\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5177 - val_accuracy: 0.7708\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7726 - val_loss: 0.5176 - val_accuracy: 0.7708\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7726 - val_loss: 0.5176 - val_accuracy: 0.7708\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7726 - val_loss: 0.5175 - val_accuracy: 0.7708\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7726 - val_loss: 0.5175 - val_accuracy: 0.7708\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7726 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7726 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.5173 - val_accuracy: 0.7708\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.5173 - val_accuracy: 0.7708\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.5172 - val_accuracy: 0.7708\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.5172 - val_accuracy: 0.7708\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7726 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.5165 - val_accuracy: 0.7708\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.5165 - val_accuracy: 0.7708\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7726 - val_loss: 0.5165 - val_accuracy: 0.7708\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7726 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7743 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7743 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7743 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7743 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7743 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7778 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7795 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7812 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7778 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7795 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7795 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7795 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7760 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7778 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7778 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7778 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7778 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7795 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.78 - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7795 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7795 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7795 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7778 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7743 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7743 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7743 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7743 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7743 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7743 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7760 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7865\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7865\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7865\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7812\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.5093 - val_accuracy: 0.7812\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7812\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7812\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5115 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e2290740a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
